# Apresenta√ß√£o:
Ol√°! üëã Me chamo Ramon, sou estudante do 4¬∫ semestre do curso de Sistemas de Informa√ß√£o na Uninassau, localizada em Salvador, Bahia. Este √© meu primeiro est√°gio na √°rea, proporcionando uma valiosa experi√™ncia profissional. Al√©m de mergulhar nos c√≥digos, sou um entusiasta de hist√≥rias em quadrinhos, encontrando inspira√ß√£o criativa nesse universo. No momento, estou aprimorando meus conhecimentos em Cloud computing  e database engineer durante o est√°gio.



# Experi√™ncia Profissional:
Atualmente, estou embarcando na minha primeira experi√™ncia profissional atrav√©s de um est√°gio. Este est√°gio tem sido uma oportunidade √∫nica para aplicar meus conhecimentos acad√™micos na pr√°tica, especialmente na explora√ß√£o de ambientes Linux e Git.

# Sprint 1:Estudos em Linux e Git
No contexto do est√°gio, estou aprimorando minhas habilidades em Linux, explorando sua arquitetura e funcionalidades. Simultaneamente, estou mergulhando nos detalhes do Git, aprimorando minha capacidade de controle de vers√£o, uma habilidade essencial para qualquer desenvolvedor.

# Sprint 2: SQL e Big Data
Durante a Sprint 2, estudei SQL e Big Data. Isso envolveu aprender a trabalhar com bancos de dados relacionais usando SQL para consultas e manipula√ß√£o de dados. Al√©m disso,  explorei conceitos e tecnologias relacionados ao processamento e an√°lise de grandes volumes de dados, conhecidos como Big Data. Isso pode incluir o aprendizado sobre ferramentas como Hadoop, Spark, ou bancos de dados NoSQL, entre outros. Aprender SQL e Big Data √© crucial para lidar com conjuntos de dados massivos e realizar an√°lises avan√ßadas para insights de neg√≥cios.

# Sprint 3: Python
Durante a Sprint 3, estudei Python. Python √© uma linguagem de programa√ß√£o poderosa e amplamente utilizada em diversas √°reas, incluindo desenvolvimento web, an√°lise de dados, automa√ß√£o, intelig√™ncia artificial, entre outros. Durante esta sprint, explorei os conceitos fundamentais de Python, como tipos de dados, estruturas de controle, fun√ß√µes, classes, manipula√ß√£o de arquivos, manipula√ß√£o de strings, tratamento de exce√ß√µes, entre outros t√≥picos. Al√©m disso, estudei sobre bibliotecas populares em Python, como Pandas para an√°lise de dados, NumPy para computa√ß√£o num√©rica, Matplotlib e Seaborn para visualiza√ß√£o de dados, e muitas outras bibliotecas √∫teis que tornam Python uma escolha poderosa para desenvolvimento e an√°lise de dados. Dominar Python √© essencial para se tornar um analista de dados eficaz e vers√°til, especialmente no contexto de ci√™ncia de dados e desenvolvimento de aplicativos baseados em dados.

# Sprint 4: Docker e Python
Na Sprint 4, estudei duas √°reas-chave: Docker e Python. Docker √© uma plataforma que permite que voc√™ empacote, distribua e execute aplicativos em cont√™ineres. Durante esta sprint, voc√™ pode terestudei  sobre os conceitos fundamentais do Docker, como cont√™ineres, imagens, volumes e redes, e como usar o Docker para criar, implantar e gerenciar aplicativos em cont√™ineres. Al√©m disso,  continuei a aprimorar suas habilidades em Python, explorando t√≥picos mais avan√ßados e aplicando-os em conjunto com o Docker para desenvolver e implantar aplicativos Python em cont√™ineres.

# Sprint 5: AWS Skill Builder
Durante a Sprint 5, estudei conceitos de Skill Builder da AWS (Amazon Web Services). Isso envolveu o aprendizado sobre os servi√ßos principais da AWS, como EC2, S3, RDS, Lambda, IAM, entre outros. isso me deixou familiarizado com os conceitos de computa√ß√£o em nuvem, arquitetura de nuvem, e como usar os servi√ßos da AWS para desenvolver, implantar e gerenciar aplicativos em nuvem. Tornar-se um Skill Builder da AWS √© uma habilidade valiosa e altamente procurada no mercado de tecnologia.

# Sprint 6: AWS Data & Analytics
Na Sprint 6, estudei sobre as solu√ß√µes de dados e an√°lises da AWS. Isso envolveu o aprendizado sobre servi√ßos como Amazon Redshift, Amazon EMR (Elastic MapReduce), Amazon Athena, Amazon Glue, entre outros. estudei como usar esses servi√ßos para processamento e an√°lise de dados em escala, constru√ß√£o de pipelines de dados, cria√ß√£o de data lakes, e implementa√ß√£o de solu√ß√µes de an√°lise avan√ßadas na AWS. Dominar as solu√ß√µes de dados e an√°lises da AWS √© crucial para lidar com grandes volumes de dados e extrair insights valiosos para o neg√≥cio.

# Sprint 7: AWS Glue, Spark e Hadoop
Durante a Sprint 7, aprofundei meus conhecimentos em AWS Glue, Apache Spark e Hadoop. AWS Glue √© um servi√ßo de ETL (Extract, Transform, Load) totalmente gerenciado pela AWS, enquanto Spark e Hadoop s√£o ferramentas amplamente utilizadas para processamento distribu√≠do de dados em grande escala. Durante esta sprint, pude estudar  como usar AWS Glue para automatizar tarefas de ETL, como usar Spark e Hadoop para processamento e an√°lise de dados distribu√≠dos, e como integrar essas tecnologias com outros servi√ßos da AWS para construir solu√ß√µes de dados robustas e escal√°veis.


# Portf√≥lio em Desenvolvimento:
Ao progredir no programa de bolsas, estou comprometido em alimentar este README para criar um portf√≥lio detalhado de meus estudos. Este portf√≥lio ser√° um registro din√¢mico da minha jornada de aprendizado, destacando projetos, desafios superados e conquistas alcan√ßadas ao longo do tempo.

Sinta-se √† vontade para acompanhar minha jornada! ‚ú®
