

import sys
from pyspark.context import SparkContext
from awsglue.context import GlueContext
from awsglue.transforms import *
from awsglue.utils import getResolvedOptions
from awsglue.job import Job
from pyspark.sql.functions import upper, desc, count
from pyspark.sql import SparkSession


sc = SparkContext()
glueContext = GlueContext(sc)
spark = glueContext.spark_session


args = getResolvedOptions(sys.argv, ['MEU_JOB'])
job_name = args['MEU_JOB']


job = Job(glueContext)
job.init(job_name, args)


input_path = "s3://my-bucket-compass/lab-glue/input/nomes.csv"
output_path = "s3://my-bucket-compass/lab-glue/frequencia_registro_nomes_eua/"


df = spark.read.csv(input_path, header=True, inferSchema=True)


print("Schema do DataFrame:")
df.printSchema()


df = df.withColumn("nome", upper(df["nome"]))


print(f"Contagem total de linhas: {df.count()}")


df_grouped = df.groupBy("ano", "sexo").agg(count("nome").alias("contagem_nomes"))
print("Contagem de nomes por ano e sexo:")
df_grouped.show()

df_sorted = df.sort(desc("ano"))

max_female_name = df_sorted.filter(df_sorted.sexo == "F").first()
print(f"Nome feminino com mais registros: {max_female_name['nome']}, Ano: {max_female_name['ano']}")

max_male_name = df_sorted.filter(df_sorted.sexo == "M").first()
print(f"Nome masculino com mais registros: {max_male_name['nome']}, Ano: {max_male_name['ano']}")

df_total_registros_por_ano = df.groupBy("ano").agg(count("nome").alias("total_registros"))
print("Total de registros por ano:")
df_total_registros_por_ano.show()

df.write.partitionBy("sexo", "ano").json(output_path)

job.commit()